{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "perfect-picnic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move: 1 ---------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17345/1540497196.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0magent_white\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCTS_Actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0magent_white\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"-50-games\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mplay_player\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_white\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_moves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"video\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Reinforcement Learning Projects/CheckersBot/gameplay_utils.py\u001b[0m in \u001b[0;36mplay_player\u001b[0;34m(agent_white, board, max_moves, visual)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mchosen_piece\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchosen_move\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchosen_take\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_white\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossible_takes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'White/Gray moves {} to {}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_piece\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchosen_move\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchosen_move\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchosen_piece\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchosen_move\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchosen_take\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Reinforcement Learning Projects/CheckersBot/agent.py\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(self, input_possible_moves, input_pieces_taken, input_board)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# update the moves for the new board\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 \u001b[0mpossible_moves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pieces_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m                 \u001b[0mnew_moves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_jump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_moves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pieces_taken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mcurrent_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_board\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Reinforcement Learning Projects/CheckersBot/board_utils.py\u001b[0m in \u001b[0;36mget_moves\u001b[0;34m(player, data, size)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_spaces\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mmoves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/RLTheory/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36many\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/RLTheory/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36many\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     \"\"\"\n\u001b[0;32m-> 2395\u001b[0;31m     return _wrapreduction(a, np.logical_or, 'any', axis, None, out,\n\u001b[0m\u001b[1;32m   2396\u001b[0m                           keepdims=keepdims, where=where)\n\u001b[1;32m   2397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/RLTheory/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### Checkers Bot\n",
    "# From the english draught rules: https://en.wikipedia.org/wiki/English_draughts\n",
    "# Use Monte Carlo Tree Search to play checkers\n",
    "\n",
    "\"\"\"\n",
    "When human playing against the computer ensure that maxNumberOutputs > 100\n",
    "otherwise you won't be able to see the move options. \n",
    "\n",
    "This can be done by going into:\n",
    "\n",
    "settings: click on Menu bar → Settings → \n",
    "Advanced Settings Editor → Notebook → \n",
    "set maxNumberOutputs in the User Preferences tab\n",
    "\n",
    "{\n",
    "\"maxNumberOutputs\": 1000\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "BUGS:\n",
    "\n",
    "self.plays[current_hash] returns 0\n",
    "-> not due to self.values[current_hash] being overwritten due to hashing func\n",
    "\n",
    "self.plays[hash_val] in backpropagate produces key error\n",
    "-> key corresponds to enemy key hash not being found during selection\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import random, math, pickle, os\n",
    "\n",
    "from board import Board\n",
    "from agent import Random_Actor, MCTS_Actor\n",
    "from gameplay_utils import train_mcts, play_game, play_player\n",
    "\n",
    "# set the parameters\n",
    "np.random.seed(1)\n",
    "random.seed(1)  \n",
    "size, max_moves, max_games = 8, 100, 100\n",
    "mode = \"human\"\n",
    "\n",
    "# initialise the players and the board    \n",
    "board = Board(size=size) \n",
    "\n",
    "# train the mcts agent\n",
    "if mode == \"train\":\n",
    "    train_mcts(\n",
    "        mcts_agent=MCTS_Actor,\n",
    "        max_games=max_games,\n",
    "        max_moves=max_moves,\n",
    "        size=size,\n",
    "        save_filename=\"test\",\n",
    "        load_filename=\"\",\n",
    "        debug=False\n",
    "    )  \n",
    "\n",
    "# play against a random player\n",
    "if mode == \"random\":\n",
    "    agent_white = MCTS_Actor(player='white', size=size)    \n",
    "    agent_black = Random_Actor('black')\n",
    "    agent_white.load_values(filename=\"-50-games\")   \n",
    "    play_game(agent_white, agent_black, board, max_moves, visual=\"pygame\")\n",
    "\n",
    "# play against a human player\n",
    "if mode == \"human\":\n",
    "    agent_white = MCTS_Actor(player='white', size=size)    \n",
    "    agent_white.load_values(filename=\"-50-games\")    \n",
    "    play_player(agent_white, board, max_moves, visual=\"pygame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f852b4-d10c-48dd-b276-ebbbf67e7c16",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Checker AI with Monte Carlo Tree Search  \n",
    "\n",
    "This is repository containing the code for playing checkers using Monte-Carlo-Tree-Search (MCTS). \n",
    "The package contains the code for:\n",
    "* Simulating the board\n",
    "* Training the MCTS agent\n",
    "* Playing the MCTS agent against a random player\n",
    "* Playing the MCTS agent against a human player\n",
    "\n",
    "Here is an example of the MCTS performance after training on only 50 games of self play:\n",
    "\n",
    "MCTS vs. Random Player           |  MCTS vs. Human Player\n",
    ":-------------------------------:|:--------------------------------:\n",
    "![](./videos/mcts_vs_random.gif) | ![](./videos/mcts_vs_player.gif)\n",
    "\n",
    "## Installation\n",
    "\n",
    "```\n",
    "conda create --name myenv python=3.7 \n",
    "conda activate myenv\n",
    "git clone https://github.com/hemerson1/MCTS-Checkers.git\n",
    "cd RLcycle\n",
    "pip install -U -r requirements.txt\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "## Licence\n",
    "\n",
    "[MIT](https://choosealicense.com/licenses/mit/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99561d9-8e03-46e7-a75f-1b7408e9cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"./videos/mcts_vs_random.gif\" width=\"256\" alt=\"this slowpoke moves\" >\n",
    "  <img src=\"./videos/mcts_vs_player.gif\" width=\"256\" alt=\"this slowpoke moves\" >\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
